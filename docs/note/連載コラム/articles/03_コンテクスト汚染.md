# #3 コンテクスト汚染 - AIを混乱させているのは、あなたの「前提」だった

**前回**、「LLMに怒る人が理解していない本質」として、**AIの出力の品質 = あなたの入力の質**という原則をお伝えしました。「AIが間違えた」と思ったら、まずは自分の与えた文脈を見直す。そういう習慣が、Context Controlの第一歩だと。

でも、「ちゃんと指示を出したつもりなのに、AIが思った通りに動いてくれない」という経験、ありませんか？

実は、あなたが何気なく与えた**「前提」や「思い込み」**が、LLMのコンテクストを**汚染**し、間違った出力を引き起こしているんです。

今回は、**Context Control訓練の第一歩**である「クリーンな文脈を保つ意識」について、3つの汚染パターンを通して理解していきましょう。

---

## コンテクスト汚染とは？ - 水槽の比喩

LLMのコンテクストを、**透明な水槽**に例えてみましょう。

- **あなたの指示**: 水槽に入れる情報（魚のエサ）
- **LLMの出力**: 水槽の中で泳ぐ魚（あなたの指示に基づいて生成される文章）
- **汚染**: 不要な情報（泥）が混入すると、水槽が濁る

水槽が濁ると、魚はうまく泳げません。同じように、**コンテクストが汚染されると、LLMは正しい出力を生成できなくなる**のです。

では、どんな「泥」がコンテクストを汚染するのか？3つのパターンを見ていきましょう。

---

## 汚染パターン1: 前提の押し付け - 「このPythonコードは...」

**シチュエーション**:
あなたがAIに質問します。

> 「このPythonコードにバグがあります。修正してください」
> ```
> function greet(name) {
>   console.log("Hello, " + name);
> }
> ```

AIは「Pythonコードを修正する」という前提で動きますが、**実際のコードはJavaScript**です。

**何が起きるか？**
- AIは「Pythonとして解釈しようとする」→混乱→不正確な出力
- あなたの**思い込み**（「これはPythonだ」）が、コンテクストを汚染している

**正しい指示**:
> 「このコードにバグがあります。修正してください」（言語を特定しない、またはコードを見せて「これは何の言語か？」と聞く）

---

## 汚染パターン2: 矛盾する指示の蓄積 - 「シンプルに」→「詳しく」→「簡潔に」

**シチュエーション**:
ChatGPTで長い会話をしているとき。

1. 最初の質問:「Reactの基礎を**シンプルに**説明して」
2. 次の質問:「もっと**詳しく**説明して」
3. さらに次:「もっと**簡潔に**まとめて」

**何が起きるか？**
- AIは「シンプル vs 詳しい vs 簡潔」という**矛盾する指示**を抱えたまま出力を生成
- コンテクストが汚染され、中途半端な出力になる

**解決策**:
- **コンテクストをリセット**:「新しい会話を始めて、最初からやり直す」
- または、**明確に上書き**:「これまでの指示を無視して、以下の指示に従ってください」

---

## 汚染パターン3: 不要な情報の混入 - 関係ない話題を挟む

**シチュエーション**:
> 「Next.jsのServer Actionsについて教えて。あと、昨日カレーを食べたんだけど、美味しかったよ。で、Server Actionsはどういう仕組み？」

**何が起きるか？**
- 「カレー」という**不要な情報**がコンテクストに混入
- AIは「カレーとServer Actionsに何か関係があるのか？」と混乱する可能性
- 水槽に泥が混ざった状態

**正しい指示**:
> 「Next.jsのServer Actionsについて、仕組みとユースケースを教えてください」

---

## Context Controlの第一歩: クリーンな文脈を保つ意識

**3つの汚染パターンから学べること**:

1. **前提を疑う**: 「これはPythonだ」という思い込みを押し付けない
2. **矛盾を避ける**: 長い会話では定期的にコンテクストをリセット
3. **不要な情報を入れない**: 関係ない話題を挟まない

**プログラミングでは、「一文字でも間違えればエラー」**。だからこそ、Context Controlの訓練として最適なんです。

- **企画書**: 曖昧でも「なんとなく」通じる
- **ビジネス文書**: 前提が共有されていれば「察して」もらえる
- **プログラミング**: 前提も思い込みも通用しない。**クリーンな文脈**を保つ訓練が強制される

---

## 実践ハック: 今日からできる「クリーンな文脈を保つ」訓練

### ステップ1: コンテクストリセットを習慣化
- ChatGPTで長い会話をしたら、定期的に「新しいチャット」を開始
- 「これまでの指示を無視して、以下に従ってください」と明示

### ステップ2: 確認型質問をする
- 「これはPythonだ」と決めつけず、「このコードは何の言語ですか？」と確認
- AIの出力が期待と違ったら、「どの部分の指示が不明確でしたか？」と聞く

### ステップ3: 指示をシンプルに
- 1つの質問に1つのトピック
- 関係ない情報を混ぜない

---

## 次回予告

コンテクスト汚染を避ける意識が身についたら、次は**「Context Control」という技術**の全体像を理解しましょう。

**次回 #4「Context Control Technology - 情報を『正しく・たくさん・いつでも・品質高く』与える技術」**では、Context Controlの4つの要素を深掘りします。

- **正しく与える**: 前提を疑い、クリーンな文脈を保つ（今回学んだこと）
- **たくさん与える**: 背景・状況・意図を詳しく伝える
- **いつでも引き出せるようにしておく**: ファイルやメモリで情報を保存
- **提供量と提供品質を担保する**: トークン制限とファイル分割の意識

この4つの要素を理解することで、AIを「共同創業者」として使いこなせるようになります。

---

**この連載は、企業が180万円/人を払う本格プログラムを、個人向けに提供する「Vibe Coder Bootcamp」のエッセンスをお届けしています。**

詳細はこちら: https://vibecoderbootcamp.com
